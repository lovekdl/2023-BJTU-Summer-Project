{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练数据处理\n",
    "\n",
    "* 处理40%以上空缺的列\n",
    "* 根据先验知识除去不需要的列\n",
    "* 添加habitable列\n",
    "* 将分类种类大于10类的列删除\n",
    "* 填补空缺项（分类列填missing，数值列填nan）\n",
    "* 剩余的分类列做one-hot编码\n",
    "* 对数据进行标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exos after removing columns with more than 15% missing data (3970, 98)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "\n",
    "hpl_data = pd.read_csv('./data/phl_exoplanet_catalog.csv')\n",
    "exoplanet_data = pd.read_csv('./data/exoplanets.csv')\n",
    "imputed_data = pd.read_csv('./data/ImputedNumericCols.csv')\n",
    "\n",
    "# 获取hpl_data中的所有可宜居星球的名字\n",
    "hpl_data = hpl_data.drop('P_STATUS', axis=1)\n",
    "habitable_data = hpl_data[hpl_data.P_HABITABLE != 0]\n",
    "habitable_planets_names = habitable_data.P_NAME.values\n",
    "\n",
    "exoplanet_data[\"habitable\"]  = exoplanet_data['pl_name'].isin(habitable_planets_names)\n",
    "\n",
    "# 合并imputed_data和exoplanet_data\n",
    "for field in imputed_data.columns:\n",
    "    if field not in exoplanet_data.columns:\n",
    "        pass\n",
    "    else:\n",
    "        exoplanet_data[field] = imputed_data[field]\n",
    "\n",
    "# 去除不需要的列        \n",
    "remove=['pl_controvflag', 'pl_letter', 'pl_discmethod', 'pl_nnotes', 'ra_str', 'dec_str', 'rowupdate', 'pl_tsystemref', \n",
    "        'pl_def_reflink', 'pl_disc', 'pl_disc_reflink', 'pl_locale', 'pl_facility', 'pl_telescope', \n",
    "        'pl_instrument', 'pl_status', 'pl_pelink', 'st_nts', 'st_nplc', 'st_nglc', 'st_nrvc', 'st_naxa', \n",
    "        'st_nimg', 'st_nspec', 'st_photn', 'st_colorn', 'pl_hostname', 'ra_str', 'dec_str', 'rowupdate', \n",
    "        'pl_def_reflink', 'pl_disc_reflink', 'pl_pelink', 'pl_edelink', 'pl_publ_date', 'hd_name', \n",
    "        'hip_name', 'st_spstr', 'swasp_id', 'pl_ttvflag', 'pl_kepflag', 'pl_k2flag', 'st_optband', 'st_metratio',\n",
    "        'pl_imgflag', 'pl_astflag', 'pl_omflag', 'pl_cbflag', 'st_tefflim', 'pl_tranmidlim', 'pl_ratrorlim',\n",
    "        'pl_ratrorlim', 'pl_mnum', 'st_plxlim', 'gaia_plxlim', 'gaia_distlim', 'st_pmralim', 'st_pmdeclim',\n",
    "        'st_pmlim', 'gaia_pmralim', 'gaia_pmdeclim', 'gaia_pmlim', 'st_logglim', 'st_metfelim', 'st_distlim',\n",
    "        'st_optmaglim', 'gaia_gmaglim', 'st_masslim', 'st_radlim', 'pl_trandurlim']\n",
    "exoplanet_data = exoplanet_data.drop(remove, axis=1)           \n",
    "\n",
    "\n",
    "# 去除超过15%缺失值的列\n",
    "def moreThan15Missing(col):\n",
    "    numMissing = len(exoplanet_data[exoplanet_data[col].isnull()])\n",
    "    if numMissing / len(exoplanet_data) > 0.15:\n",
    "        return 1\n",
    "    return 0\n",
    "       \n",
    "SignificantMissingData = [x for x in exoplanet_data.columns if moreThan15Missing(x)]\n",
    "exoplanet_data = exoplanet_data.drop(SignificantMissingData, axis=1)\n",
    "\n",
    "print(\"exos after removing columns with more than 15% missing data\",\n",
    "       exoplanet_data.shape) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3970, 97)\n",
      "(3970, 96)\n",
      "(3970, 96)\n"
     ]
    }
   ],
   "source": [
    "# 获取分类列\n",
    "Cat = [x for x in exoplanet_data.columns if x not in exoplanet_data._get_numeric_data().columns]\n",
    "for field in Cat:\n",
    "    if(len(exoplanet_data[field].unique()) > 10):\n",
    "        exoplanet_data = exoplanet_data.drop(field, axis=1)\n",
    "Cat = [x for x in exoplanet_data.columns if x not in exoplanet_data._get_numeric_data().columns]\n",
    "\n",
    "print(exoplanet_data.shape)\n",
    "\n",
    "# 填充缺失值\n",
    "for field in exoplanet_data.columns:\n",
    "    if(field in Cat):\n",
    "        exoplanet_data[field] = pd.Categorical(exoplanet_data[field])\n",
    "        exoplanet_data[field] = exoplanet_data[field].cat.add_categories(\"Missing\").fillna(\"Missing\")\n",
    "    else: \n",
    "        exoplanet_data[field] = exoplanet_data[field].fillna(np.nan)\n",
    "        \n",
    "# 将rowid设置为索引\n",
    "exoplanet_data = exoplanet_data.set_index(\"rowid\")\n",
    "\n",
    "# print(exoplanet_data.columns)\n",
    "\n",
    "# 对可宜居星球和不可宜居星球做分别做处理\n",
    "habitable = exoplanet_data[exoplanet_data.habitable == True]\n",
    "nonHabitable = exoplanet_data[~exoplanet_data.habitable == True]\n",
    "\n",
    "# 用中位数填补空缺值\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'median') \n",
    "# habitable[habitable._get_numeric_data().columns] = imputer.fit_transform(habitable[habitable._get_numeric_data().columns])\n",
    "# nonHabitable[nonHabitable._get_numeric_data().columns] = imputer.fit_transform(nonHabitable[nonHabitable._get_numeric_data().columns])\n",
    "# imputer.fit(exoplanet_data[exoplanet_data._get_numeric_data().columns])\n",
    "exoplanet_data[exoplanet_data._get_numeric_data().columns] = imputer.fit_transform(exoplanet_data[exoplanet_data._get_numeric_data().columns])\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(imputer, './model/imputer.joblib') \n",
    "\n",
    "# Join the two datasets\n",
    "# tempExos = pd.concat([habitable,nonHabitable])\n",
    "\n",
    "# for field in tempExos.columns:\n",
    "#     if(field in exoplanet_data.columns):\n",
    "#         exoplanet_data[field] = tempExos[field]\n",
    "#     else:\n",
    "#         print(field)\n",
    "        \n",
    "        \n",
    "#Scale the data so that it has unit variance\n",
    "NumericCols=[]\n",
    "for n in exoplanet_data._get_numeric_data().columns:\n",
    "\t#Dont scale binary columns(ie those that only have 1 or 0)\n",
    "    if not (list(exoplanet_data[n].unique()) == [0,1]):\n",
    "        NumericCols.append(n)\n",
    "scaler = StandardScaler()\n",
    "exoplanet_data[NumericCols] = scaler.fit_transform(exoplanet_data[NumericCols])\n",
    "\n",
    "with open('./model/NumericCols.pkl', 'wb') as f:\n",
    "    pickle.dump(NumericCols, f)\n",
    "# 保存模型\n",
    "joblib.dump(scaler, './model/scaler.joblib')\n",
    "\n",
    "print(exoplanet_data.shape)\n",
    "\n",
    "#One hot encode categorical columns\n",
    "preprocessed = pd.get_dummies(exoplanet_data)\n",
    "\n",
    "print(preprocessed.shape)\n",
    "\n",
    "preprocessed.to_csv('./preprocessed22222222.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
